{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Indexing\n",
    "\n",
    "We'll explore how queries are executed in SQLite. After exploring this at a high level, we will explore how to create and use indexes for better performance. As our data gets larger and our queries more complex, it's important to be able to tweak the queries we write and optimize a database's schema to ensure that we're getting results back quickly.\n",
    "\n",
    "To explore database performance, we'll work with `factbook.db`, a SQLite database that contains information about each country in the world. We'll be working with the `facts` table in the database. Each row in `facts` represents a single country, and contains several columns, including:\n",
    "\n",
    "- `name` -- the name of the country.\n",
    "- `area` -- the total land and sea area of the country.\n",
    "- `population` -- the population of the country.\n",
    "- `birth_rate` -- the birth rate of the country.\n",
    "- `created_at` -- the date the record was created.\n",
    "- `updated_at` -- the date the record was updated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "conn = sqlite3.connect(\"factbook.db\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Write a query that returns the schema of the `facts` table and assign the resulting list of tuples to `schema`.\n",
    "- Use a `for` loop and a `print` statement to display each tuple in `schema` on a separate line.\n",
    "\n",
    "To return the schema of a table, use the PRAGMA statement followed by the TABLE_INFO argument. [Documentation](https://www.sqlite.org/pragma.html#pragma_table_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 'id', 'INTEGER', 1, None, 1)\n",
      "(1, 'code', 'varchar(255)', 1, None, 0)\n",
      "(2, 'name', 'varchar(255)', 1, None, 0)\n",
      "(3, 'area', 'integer', 0, None, 0)\n",
      "(4, 'area_land', 'integer', 0, None, 0)\n",
      "(5, 'area_water', 'integer', 0, None, 0)\n",
      "(6, 'population', 'integer', 0, None, 0)\n",
      "(7, 'population_growth', 'float', 0, None, 0)\n",
      "(8, 'birth_rate', 'float', 0, None, 0)\n",
      "(9, 'death_rate', 'float', 0, None, 0)\n",
      "(10, 'migration_rate', 'float', 0, None, 0)\n"
     ]
    }
   ],
   "source": [
    "schema = conn.execute(\"pragma table_info(facts);\").fetchall()\n",
    "for s in schema:\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you execute a SQL query, SQLite performs many steps before returning the results to you. First, it tokenizes and parses your query to look for any syntax errors. If there are any syntax errors, the query execution process halts and the error message is returned to you. If the parser was able to successfully parse the query, then SQLite moves on to the query planning and optimization phase.\n",
    "\n",
    "There are many different ways for SQLite to access the underlying data in a database. When working with a database that's stored on disk as a file, it's crucial to minimize the amount of disk reads necessary to avoid long running times. The `query optimizer` generates cost estimates for the various ways to access the underlying data, factoring in the schema of the tables and the operations the query requires. The heuristics and algorithms that are involved in query optimization is complex and out of this mission's scope.\n",
    "\n",
    "The optimizer quickly assesses the various ways to access the data and generates a best guess for the fastest `query plan`. This high level query plan is then converted into highly efficient, lower-level C code to interact with the database file on disk. Thankfully, we can observe the query plan to understand what SQLite is doing to return our results.\n",
    "\n",
    "## Query Planner\n",
    "\n",
    "When you execute a SQL query, SQLite performs many steps before returning the results to you. First, it tokenizes and parses your query to look for any syntax errors. If there are any syntax errors, the query execution process halts and the error message is returned to you. If the parser was able to successfully parse the query, then SQLite moves on to the query planning and optimization phase.\n",
    "\n",
    "There are many different ways for SQLite to access the underlying data in a database. When working with a database that's stored on disk as a file, it's crucial to minimize the amount of disk reads necessary to avoid long running times. The **query optimizer** generates cost estimates for the various ways to access the underlying data, factoring in the schema of the tables and the operations the query requires. The heuristics and algorithms that are involved in query optimization is complex and out of this mission's scope.\n",
    "\n",
    "The optimizer quickly assesses the various ways to access the data and generates a best guess for the fastest **query plan**. This high level query plan is then converted into highly efficient, lower-level C code to interact with the database file on disk. Thankfully, we can observe the query plan to understand what SQLite is doing to return our results.\n",
    "\n",
    "## Explaining Query Plan\n",
    "\n",
    "We can use the `EXPLAIN QUERY PLAN` statement before any query we're running to get a high level query plan that would be performed. If you write a `SELECT` statement and place the `EXPLAIN QUERY PLAN` statement before it:\n",
    "\n",
    "`EXPLAIN QUERY PLAN SELECT * FROM facts;`\n",
    "\n",
    "the results of the `SELECT` query won't be returned and instead the high level query plan will be:\n",
    "\n",
    "`[(0, 0, 0, 'SCAN TABLE facts')]`\n",
    "\n",
    "In this mission, we'll focus on `'SCAN TABLE facts'`, the last value from the returned tuple. `SCAN TABLE` means that every row in the entire table (`facts`) had to be accessed to evaluate the query. Since the `SELECT` query we wrote returns all of the columns and rows in the `facts` table, the entire table had to be accessed to get the results we requested.\n",
    "\n",
    "When running the query using the sqlite3 library, you'll still need to use the `fetchall()` method.\n",
    "\n",
    "```\n",
    "query_plan = conn.execute(\"EXPLAIN QUERY PLAN SELECT * FROM facts;\").fetchall()\n",
    "```\n",
    "\n",
    "The query plan is represented as a tuple, which is the sqlite3 library's preferred way of representing results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(2, 0, 0, 'SCAN TABLE facts')]\n"
     ]
    }
   ],
   "source": [
    "query_plan = conn.execute(\"EXPLAIN QUERY PLAN SELECT * FROM facts;\").fetchall()\n",
    "print(query_plan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Return the query plan for the query that returns all columns and rows where `area` exceeds **40000**. Assign the results to `query_plan_one`.\n",
    "- Return the query plan for the query that returns only the `area` column for all rows where `area` exceeds **40000**. Assign the results to `query_plan_two`.\n",
    "- Return the query plan for the query that returns the row for the country **Czech Republic**. Assign the results to `query_plan_three`.\n",
    "- Use the `print` function to display each query plan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(2, 0, 0, 'SCAN TABLE facts')]\n",
      "[(2, 0, 0, 'SCAN TABLE facts')]\n",
      "[(2, 0, 0, 'SCAN TABLE facts')]\n"
     ]
    }
   ],
   "source": [
    "query_plan_one = conn.execute(\"explain query plan select * from facts where area > 40000;\").fetchall()\n",
    "query_plan_two = conn.execute(\"explain query plan select area from facts where  area > 40000;\").fetchall()\n",
    "query_plan_three = conn.execute(\"explain query plan select name from facts where name = 'Czech';\").fetchall()\n",
    "print(query_plan_one)\n",
    "print(query_plan_two)\n",
    "print(query_plan_three)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data representation\n",
    "\n",
    "You'll notice that all 3 query plans are exactly the same. The entire `facts` table had to be accessed to return the data we needed for all 3 queries. Even though all the queries asked for a subset of the `facts` table, SQLite still ends up scanning the entire table. Why is this? This is because of the way SQLite represents data.\n",
    "\n",
    "For the `facts` table, we set the `id` column as the primary key and SQLite uses this column to order the records in the database file. Since the rows are ordered by `id`, SQLite can search for a specific row based on it's `id` value using binary search. Unless we provide specific `id` values in the `WHERE` statement in the query, SQLite can't take advantage of binary search and has to instead scan the entire table, row by row. To return the results for the first 2 queries, SQLite has to:\n",
    "\n",
    "- access the first row in the table (lowest `id` value),\n",
    "    - check if that row's value for `area` exceeds **40000** and store the row separately in a temporary collection if it is,\n",
    "- move onto the next row,\n",
    "    - check if that row's value for `area` exceeds **40000** and store the row separately in a temporary collection if it is,\n",
    "- repeat moving and checking each row for the rest of the table,\n",
    "- return the final collection of rows that meet the criteria.\n",
    "\n",
    "If we were instead interested in a row with a specific `id` value, like in the following query:\n",
    "\n",
    "`SELECT * FROM facts WHERE id=15;`\n",
    "\n",
    "SQLite can use binary search to quickly find the corresponding row at that `id` value. Instead of performing a full table scan, SQLite would:\n",
    "\n",
    "- use binary search to find the first row where the `id` value matches `15` in `O(log N)` time complexity and store this row in a temporary collection,\n",
    "- advance to the next row to look for any more rows with the same `id` values and add those rows to the temporary collection,\n",
    "- return the final collection of rows that matched.\n",
    "\n",
    "If we set the `id` column to be a `UNIQUE PRIMARY KEY` when we created the schema, SQLite would stop searching when it found the instances that matched the `id` value. It would avoid advancing to the next row(s) since no 2 rows could have the same `id` value. While we didn't enforce the `UNIQUE` constraint on the `id` column, all of the values currently in the column are in fact unique and SQLite will only have to advance one row to realize this since they're ordered.\n",
    "\n",
    "## Time Complexity\n",
    "\n",
    "\n",
    "Binary search on a table using the primary key would be `O(log N)` time complexity where `N` is the number of total rows in the table. On the other hand, a full table scan would would be `O(N)` time complexity since each row would have to be accessed. If we're working with a database containing millions of rows, binary search would be over a million times faster! While you may not notice major performance differences when working with a small, on-disk database, they become profound as you scale up the amount of data you work with. Many organizations work with databases that contains billions or trillions of rows and understanding the time complexity of queries is important to avoid writing queries that take a long time to complete.\n",
    "\n",
    "Let's now observe the query plan that SQLite takes to access a row at a specific `id` value.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(2, 0, 0, 'SEARCH TABLE facts USING INTEGER PRIMARY KEY (rowid=?)')]\n"
     ]
    }
   ],
   "source": [
    "query_plan_four = conn.execute(\"explain query plan select * from facts where id = 20;\").fetchall()\n",
    "print(query_plan_four)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search and Rowid\n",
    "\n",
    "Instead of using a full table scan:\n",
    "\n",
    "`[(0, 0, 0, 'SCAN TABLE facts')]`\n",
    "\n",
    "SQLite performed binary search on the `facts` table using the integer primary key:\n",
    "\n",
    "`[(0, 0, 0, 'SEARCH TABLE facts USING INTEGER PRIMARY KEY (rowid=?)')]`\n",
    "\n",
    "SQLite uses `rowid` to refer to the primary key of a table. The alias `rowid` will be displayed in the query plan, no matter what you name the primary key column for that table. Either `SCAN` or `SEARCH` will always appear at the start of the query explanation for `SELECT` queries.\n",
    "\n",
    "## Indexing\n",
    "\n",
    "SQLite can take advantage of speedy lookups when searching for a specific primary key. Unfortunately, we don't always have the primary keys for the rows we're interested in beforehand. When we're expressing our intent as a SQL query, we're often thinking in terms of row and column values. We need to find a way that allows us to benefit from the speed of primary key lookups without actually knowing the primary key in advance.\n",
    "\n",
    "To that end, we could create a separate table that's optimized for lookups by a different column from the `facts` table instead of by the `id`. We can make the column we want to query by the primary key, so we get the speed benefits, and embed the `id` value from the `facts` table corresponding to that row. We call this table an **index** and each row in the index contains:\n",
    "\n",
    "- the value we want to be able to search by, as the primary key,\n",
    "- an `id` value for the corresponding row in `facts`.\n",
    "\n",
    "Let's walk through a concrete example. If we wrote a `SELECT` query to look up the population of **India** from the `facts` table:\n",
    "\n",
    "`SELECT population FROM facts WHERE name = 'India';`\n",
    "\n",
    "SQLite would need to perform a full table scan on `facts` to find the specific row where the value for `name` was **India**. We can instead create an index that's ordered by `name` values (primary key) and where each row contains the corresponding row's `id` from the `facts` table.\n",
    "\n",
    "# CREATE AN INDEX\n",
    "\n",
    "We can write a query that uses the primary key, the country name, of the index table, which we'll call `name_idx`, to look up the row we're interested in and then extract the `id` value for that row in `facts`. Then, we can write a separate query that uses the `id` value returned from the previous query to look up the specific row in the `facts` table that contains information on **India** and then return just the `population` value.\n",
    "\n",
    "Instead of performing a single full table scan of `facts`, SQLite would perform a binary search on the index then another binary search on `facts` using the `id` value. Both queries are taking advantage of the primary key for the index and the `facts` table to quickly return the results we want. Here's a diagram of these concepts:\n",
    "\n",
    "Instead of creating a separate table and updating it ourselves, we can specify a column we want an index table for and SQLite will take care of the rest. SQLite, and most databases, make it easy for you to create indexes for tables on columns we plan to query often. To create an index we use the `[CREATE INDEX` statement](https://www.sqlite.org/lang_createindex.html). Here's the pseudo-code for that statement:\n",
    "\n",
    "`CREATE INDEX index_name ON table_name(column_name);`\n",
    "\n",
    "As you can see from the pseudo-code above, each index we create needs a name (to replace `index_name`). Similar to when you add a table to a database, using the `IF NOT EXISTS` clause helps you avoid attempting to create an index that already exists. Doing so will cause SQLite to throw an error. To create an index for the `area` column called `area_idx`, we write the following query:\n",
    "\n",
    "`CREATE INDEX IF NOT EXISTS area_idx ON facts(area);`\n",
    "\n",
    "An empty array will be returned when you run the query. The main benefit of having SQLite handle the maintenance of indexes we create is that the indexes are used automatically when we execute a query whenever there will be any speed advantages. As our queries become more complex, letting SQLite decide how and when to use the indexes we create helps us be much more productive.\n",
    "\n",
    "If we create an index for the `area` column in the `facts` table, SQLite will use the index whenever we search for rows in `facts` using that column. This index would be similar to the one we worked with in the past step and each row would only contain the `area` value and the corresponding row's `id` value. The index would be ordered by the `area` values for quick lookups.\n",
    "\n",
    "All three of the following queries would take advantage of the `area_idx` index:\n",
    "\n",
    "```\n",
    "SELECT * FROM facts WHERE area = 10000;\n",
    "SELECT * FROM facts WHERE area > 10000;\n",
    "SELECT * FROM facts WHERE area < 10000;\n",
    "```\n",
    "\n",
    "Since the `area_idx` index would be ordered by the `area` values, SQLite would:\n",
    "\n",
    "- search for the first instance in the index where `area` equaled `10000` and store the `id` value in a temporary collection.\n",
    "- it would then advance to the next row in the index to check if the `WHERE` condition was still met.\n",
    "    - if not, then the temporary collection would be returned and the process completes.\n",
    "    - if so, then SQLite would add that `id` value to the collection and check the next row.\n",
    "- when SQLite finds a value for `area` that doesn't match the `WHERE` condition,\n",
    "    - it will look up and return the rows in `facts` using the `id` values stored in the temporary collection.\n",
    "    - each of these lookups will be `O(log N)` time complexity and while this could add up, it will still be faster than a full table scan.\n",
    "\n",
    "This process allows us to just write one query instead of 2 and have SQLite maintain and interact with the index. A table can have many indexes, and most tables in production environments usually do have many indexes. Every time you add or delete a row to the table, all of the indexes will be updated. If you edit the values in a row, SQLite will figure out which indexes are affected by the changes and update those indexes.\n",
    "\n",
    "While creating indexes gives us tremendous speed benefits, they come at the cost of space. Each index needs to be stored in the database file. In addition, adding, editing, and deleting rows takes longer since each of the affected indexes need to be updated. Since indexes can be created after a table is created, it's recommended to only create an index when you find yourself querying on a specific column frequently. Throughout the rest of the course, we'll explore how to understand the tradeoffs and you'll develop a better sense of how to create indexes in an optimal way.\n",
    "\n",
    "Now it's your turn to practice creating an index.\n",
    "\n",
    "## All together \n",
    "\n",
    "Instead of performing a full table scan on `facts`, SQLite used the `name_idx` index to return the `id` values first (in this case just one `id` value). Then, SQLite used binary search to extract just the rows from the `facts` table that corresponded to that `id`. SQLite utilized 2 binary searches instead of a full table scan to find the row corresponding to **India**.\n",
    "\n",
    "Let's now synthesize the concepts we learned in this mission to practice understanding the query plan and creating an index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(2, 0, 0, 'SCAN TABLE facts')]\n",
      "[(3, 0, 0, 'SEARCH TABLE facts USING INDEX pop_idx (population>?)')]\n"
     ]
    }
   ],
   "source": [
    "query_plan_six = conn.execute(\"explain query plan select * from facts where population > 10000;\").fetchall()\n",
    "print(query_plan_six)\n",
    "\n",
    "conn.execute(\"CREATE INDEX IF NOT EXISTS pop_idx ON facts(population);\")\n",
    "\n",
    "query_plan_seven = conn.execute(\"explain query plan select * from facts where population > 10000;\").fetchall();\n",
    "print(query_plan_seven)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of ending in USING INDEX pop_idx (population), the query plan ended in USING INDEX pop_idx (population>?). This is to indicate the granularity of the lookup that SQLite had to do for that index.\n",
    "\n",
    "In this mission, we explored how SQLite accessed data and how to create and take advantages of indexes. In the next mission, we'll learn how to create more complex indexes and dive deeper into database performance and learn about multi-column indices.\n",
    "\n",
    "# Introduction to Indexing: Takeaways\n",
    "\n",
    "\n",
    "## **Syntax**\n",
    "\n",
    "- Listing what SQLite is doing to return our results:\n",
    "\n",
    "    **`EXPLAIN QUERY PLAN SELECT * FROM facts;`**\n",
    "\n",
    "- Creating an index:\n",
    "\n",
    "    **`CREATE INDEX index_name ON table_name(column_name);`**\n",
    "\n",
    "- Creating an index if it does not exist:\n",
    "\n",
    "    **`CREATE INDEX IF NOT EXISTS area_idx ON facts(area);`**\n",
    "\n",
    "## **Concepts**\n",
    "\n",
    "- Your query in SQLite is tokenized and parsed to look for any syntax errors before returning the results to you. If there are any syntax errors, the query execution halts and an error message is returned to you.\n",
    "- You should minimize the amount of disk reads necessary when working with a database stored on disk.\n",
    "- The query optimizer generates cost estimates for the various ways to access the underlying data, factoring in the schema of the tables and the operations the query requires. The optimizer quickly assesses the various ways to access the data and generate a best guess for the fastest query plan.\n",
    "- SQLite still scans the entire table. A full table scan has time complexity O(n) where **`n`** is the number of total rows in the table.\n",
    "\n",
    "   ` O(n)`\n",
    "\n",
    "- Binary search of a table using the primary key would be O(logn) where n is the number of total rows in the table. Binary search on a primary key would be over a million times faster when working on a database with millions of rows compared to doing a full table scan.\n",
    "\n",
    "   ` O(log⁡n)`\n",
    "\n",
    "    \n",
    "\n",
    "- Either **`SCAN`** or **`SEARCH`** will always appear at the start of the query explanation for **`SELECT`** queries.\n",
    "- An index table is optimized for lookups by the primary key.\n",
    "\n",
    "## **Resources**\n",
    "\n",
    "- [What is an index?](https://stackoverflow.com/questions/2955459/what-is-an-index-in-sql)\n",
    "- [Query Plan](https://en.wikipedia.org/wiki/Query_plan)\n",
    "- [Time Complexity](https://en.wikipedia.org/wiki/Time_complexity)\n",
    "\n",
    "# MULTI COLUMN INDEXING\n",
    "\n",
    "In the last mission, we explored how to speed up SELECT queries that only filter on one column by creating an index for that column. In this mission, we'll explore how to create indexes for speeding up queries that filter on multiple columns.\n",
    "\n",
    "We'll continue to work with factbook.db, a SQLite database that contains information about each country in the world. Recall that this database contains just the facts table and each row represents a single country. While we created indexes for the facts table in this database in the previous mission, this version of factbook.db contains no indexes.\n",
    "\n",
    "Here are some of the columns:\n",
    "\n",
    "- name -- the name of the country.\n",
    "\n",
    "- area -- the total land and sea area of the country.\n",
    "\n",
    "- population -- the population of the country.\n",
    "\n",
    "- birth_rate -- the birth rate of the country.\n",
    "\n",
    "- created_at -- the date the record was created.\n",
    "\n",
    "- updated_at -- the date the record was updated.\n",
    "\n",
    "\n",
    "We limited ourselves to working with queries that only filtered on one column like:\n",
    "\n",
    "`SELECT * FROM facts WHERE name = 'India';`\n",
    "\n",
    "In this mission, we'll explore how to create indexes for speeding up queries that filter on multiple columns, like:\n",
    "\n",
    "`SELECT * FROM facts WHERE population > 1000000 AND population_growth < 2.0;`\n",
    "\n",
    "We'll also explore how to modify the queries we write to better take advantage of indexes. For example, if we create an index for the name column, we'll explore why the following query:\n",
    "\n",
    "`SELECT name from facts WHERE name = 'India';`\n",
    "\n",
    "will be faster than :\n",
    "\n",
    "`SELECT * from facts WHERE name = 'India';`\n",
    "\n",
    "To start, let's write and run a query that involves filtering on more than 1 column and use the EXPLAIN QUERY PLAN statement to understand what SQLite is doing to return the results. Our intuition suggests that SQLite will have to perform a full table scan. It will have to check if each row in the table meets the WHERE constraints since there are no indexes in the table to take advantage of."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(3, 0, 0, 'SEARCH TABLE facts USING INDEX pop_idx (population>?)')]\n"
     ]
    }
   ],
   "source": [
    "query_plan_one = conn.execute(\"explain query plan select * from facts where population > 1000000 and population_growth < 0.05;\").fetchall()\n",
    "print(query_plan_one)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, SQLite had to perform a full table scan to access the data we asked for. Let's add indexes for both the `population` and `population_growth` columns to see how SQLite uses these indexes for returning the same query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(3, 0, 0, 'SEARCH TABLE facts USING INDEX pop_growth_idx (population_growth<?)')]\n"
     ]
    }
   ],
   "source": [
    "conn.execute(\"create index if not exists pop_idx on facts(population);\").fetchall()\n",
    "conn.execute(\"create index if not exists pop_growth_idx on facts(population_growth);\").fetchall()\n",
    "query_plan_two = conn.execute(\"explain query plan select * from facts where population > 1000000 and population_growth < 0.05;\").fetchall()\n",
    "print(query_plan_two)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you recall, SQLite returns only a high-level query plan when you use the `EXPLAIN QUERY PLAN` statement in front of a query. This means that you'll often have to augment the returned query plan with your own understanding of the available indexes. In this case, the `facts` table has 2 indexes:\n",
    "\n",
    "- one ordered by `population` called `pop_idx`,\n",
    "- one ordered by `population_growth`, called `pop_growth_idx`.\n",
    "\n",
    "SQLite struggles to take advantage of both indexes since each index is optimized for lookups on just that column. SQLite can use the indexes to quickly find the row `id` values where *either* `population` is greater than **1000000** *or* where `population_growth` is less than **0.05**. If SQLite uses the index of `population` values to return all of the row `id` values where `population` is less than **1000000**, it can't use those `id` values to search the `pop_growth_idx` index quickly to find the rows where `population_growth` is less than **0.05**.\n",
    "\n",
    "If you look at the query plan, you can infer that SQLite first decided to use the `pop_growth_idx` index to return the `id` values for the rows where `population_growth` was less than **0.05**. Then, SQLite used a binary search on the `facts` table to access the row at each `id` value, add that row to a temporary collection if the value for `population` was greater than **1000000**, and return the collection of rows.\n",
    "\n",
    "You may be wondering why SQLite chose the `pop_growth_idx` instead of the `pop_idx`. This is because when there are 2 possible indexes available, SQLite tries to estimate which index will result in better performance. Unfortunately, to keep SQLite lightweight, limited ability was added to estimate and plan accurately and SQLite often ends up picking an index at random.\n",
    "\n",
    "## Multi column index\n",
    "\n",
    "In cases like this, we need to create a **multi-column** index that contains values from both of the columns we're filtering on. This way, both criteria in the `WHERE` statement can be evaluted in the index itself and the `facts` table will only be queried at the end when we have the specific row `id` values.\n",
    "\n",
    "While the single column indexes we've created in the past contain just the primary key column (`population`) and the row id (`id`) columns, this multi-column index contains the `population_growth` column as well. SQLite can:\n",
    "\n",
    "- use binary search to find the first row in this index where `population` is greater than **1000000**,\n",
    "- add the row to a temporary collection if `population_growth` is less than **0.05**,\n",
    "- advance to the next row (the index is ordered by `population`),\n",
    "- add the row to a temporary collection if `population_growth` is less than **0.05**,\n",
    "- when the end of the index is reached, look up each row in `facts` using the `id` values from the temporary collection.\n",
    "\n",
    "This way the `facts` table is only accessed at the end and the index is used to process the `WHERE` criteria.\n",
    "\n",
    "When creating a multi-column index, we need to specify which of the columns we want as the primary key. In the example above, this means that SQLite can use binary search to quickly jump to the first row that matches a specific `population` value but not before jumping to the first row that matches a specific `population_growth` value.\n",
    "\n",
    "To create a multi-column index, we use the same `CREATE INDEX` syntax as before but instead specify 2 columns in the `ON` statement:\n",
    "\n",
    "```\n",
    "CREATE INDEX index_name ON table_name(column_name_1, column_name_2);\n",
    "```\n",
    "\n",
    "The important thing to know here is that the first column in the parentheses becomes the primary key for the index. Let's create a multi-column index for the `population` and `population_growth` columns and return the query plan for the query we've been working with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(3, 0, 0, 'SEARCH TABLE facts USING INDEX pop_pop_growth_idx (population>?)')]\n"
     ]
    }
   ],
   "source": [
    "conn.execute(\"create index if not exists pop_pop_growth_idx on facts(population, population_growth);\").fetchall()\n",
    "query_plan_three =conn.execute(\"explain query plan select * from facts where population > 1000000 and population_growth < 0.05;\").fetchall()\n",
    "print(query_plan_three)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Covering Index\n",
    "\n",
    "This time, SQLite used the multi-column index `pop_pop_growth_idx` that we created instead of either `pop_growth_idx` or `pop_idx`. SQLite only needed to access the `facts` table to return the rest of the column values for the rows that met the `WHERE` criteria. This is only because the `pop_pop_growth_idx` doesn't contain the other values (besides `population` and `population_growth` already).\n",
    "\n",
    "What if we restricted the columns in the `SELECT` that we want returned to just `population` and `population_growth`? In this case, SQLite will not need to interact with the `facts` table since the `pop_pop_growth_idx` can service the query. When an index contains all of the information necessary to answer a query, it's called a **covering index**. Since the index *covers* for the actual table and can return the requested results to the query, SQLite doesn't need to query the actual table. For many queries, especially as your data gets larger, this can be much more efficient.\n",
    "\n",
    "Let's write a query that uses the index we created as a covering index and return its query plan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(2, 0, 0, 'SEARCH TABLE facts USING COVERING INDEX pop_pop_growth_idx (population>?)')]\n"
     ]
    }
   ],
   "source": [
    "conn.execute(\"create index if not exists pop_pop_growth_idx on facts(population, population_growth);\")\n",
    "query_plan_four = conn.execute(\"explain query plan select population, population_growth from facts where population > 1000000 and population_growth < 0.05;\").fetchall()\n",
    "print(query_plan_four);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Covering index for a single column\n",
    "\n",
    "There's two things that stand out from the query plan from the previous screen:\n",
    "\n",
    "- instead of `USING INDEX` the query plan says `USING COVERING INDEX`,\n",
    "- the query plan still contains `SEARCH TABLE facts` as before.\n",
    "\n",
    "Even though the query plan indicates that a binary search on `facts` was performed, this is misleading and it was instead able to use the covering index. You can read more about that [on the documentation](https://www.sqlite.org/queryplanner.html#covidx).\n",
    "\n",
    "Covering indexes don't apply just to multi-column indexes. If a query we write only touches a column in the database that we have a single-column index for, SQLite will use only the index to service the query. Let's test this by writing a query that can take advantage of just the index, `pop_idx`, for the `population` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(2, 0, 0, 'SEARCH TABLE facts USING COVERING INDEX pop_idx (population>?)')]\n"
     ]
    }
   ],
   "source": [
    "conn.execute(\"create index if not exists pop_pop_growth_idx on facts(population, population_growth);\")\n",
    "query_plan_five = conn.execute(\"explain query plan select population from facts where population > 1000000;\").fetchall()\n",
    "print(query_plan_five);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since only the `population` values were necessary to service the query, SQLite used the `pop_idx` index as a covering index and didn't have to access the `facts` table.\n",
    "\n",
    "In this mission, we explored how to create multi-column indexes and how to restrict our query to utilize an index if we don't always need information on column values only available in the table.\n",
    "\n",
    "# Multi-column indexing: Takeaways\n",
    "\n",
    "\n",
    "## **Syntax**\n",
    "\n",
    "- Creating a multi-column index:\n",
    "\n",
    "    **`CREATE INDEX index_name ON table_name(column_name_1, column_name_2);`**\n",
    "\n",
    "## **Concepts**\n",
    "\n",
    "- When there are two possible indexes available, SQLite tries to estimate which index will result in better performance. However, SQLite is not good at estimating and will often end up picking an index at random.\n",
    "- Use a multi-column index when data satisfying multiple conditions, in multiple columns, is to be retrieved.\n",
    "- When creating a multi-column index, the first column in the parentheses becomes the primary key for the index.\n",
    "- A covering index contains all the information necessary to answer a query.\n",
    "- Covering indexes don't apply just to multi-column indexes.\n",
    "\n",
    "## **Resources**\n",
    "\n",
    "- [Multi-Column Indexes](https://www.sqlite.org/queryplanner.html#_multi_column_indices)\n",
    "- [SQLite Index](http://www.sqlitetutorial.net/sqlite-index/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
